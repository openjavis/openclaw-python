"""
æˆåŠŸæµ‹è¯• - ä½¿ç”¨æ­£ç¡®çš„æ¨¡å‹åç§°
"""

import asyncio
import os
from pathlib import Path

from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
env_path = Path(__file__).parent / ".env"
load_dotenv(env_path)


async def test_gemini_chat():
    """æµ‹è¯• Gemini å¯¹è¯"""
    
    print("=" * 60)
    print("ğŸ¤– ClawdBot - Gemini å¯¹è¯æµ‹è¯•")
    print("=" * 60)
    print()
    
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("âŒ æœªæ‰¾åˆ° GOOGLE_API_KEY")
        return
    
    print(f"âœ… API Key å·²åŠ è½½")
    print()
    
    try:
        from openclaw.agents.providers.gemini_provider import GeminiProvider
        from openclaw.agents.providers.base import LLMMessage
        
        # ä½¿ç”¨ Gemini 2.5 Flash (æœ€æ–°ç¨³å®šç‰ˆæœ¬)
        model_name = "models/gemini-2.5-flash"
        
        print(f"ğŸ”§ åˆ›å»º Provider: {model_name}")
        provider = GeminiProvider(
            model=model_name,
            api_key=api_key
        )
        print("âœ… Provider åˆ›å»ºæˆåŠŸ")
        print()
        
        # å‡†å¤‡æµ‹è¯•å¯¹è¯
        messages = [
            LLMMessage(
                role="user", 
                content="ä½ å¥½ï¼æˆ‘æ˜¯ ClawdBot é¡¹ç›®çš„å¼€å‘è€…ã€‚è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ï¼Œä½ èƒ½å¸®æˆ‘åšä»€ä¹ˆï¼Ÿè¯·ç”¨ä¸­æ–‡å›å¤ã€‚"
            )
        ]
        
        print("ğŸ’¬ å‘é€æ¶ˆæ¯: \"ä½ å¥½ï¼æˆ‘æ˜¯ ClawdBot é¡¹ç›®çš„å¼€å‘è€…...\"")
        print("-" * 60)
        print()
        
        # è·å–å›å¤
        response_parts = []
        
        async for response in provider.stream(messages, max_tokens=500):
            if response.type == "text_delta":
                text = response.content
                response_parts.append(text)
                print(text, end="", flush=True)
            elif response.type == "done":
                break
            elif response.type == "error":
                print(f"\nâŒ é”™è¯¯: {response.content}")
                return
        
        full_response = "".join(response_parts)
        print()
        print()
        print("-" * 60)
        print("âœ… å¯¹è¯æˆåŠŸï¼")
        print()
        print("ğŸ“Š ç»Ÿè®¡:")
        print(f"   å›å¤é•¿åº¦: {len(full_response)} å­—ç¬¦")
        print(f"   å›å¤å­—æ•°: {len(full_response.replace(' ', ''))} å­—")
        print()
        
        # å†é—®ä¸€ä¸ªé—®é¢˜
        print("ğŸ’¬ ç»§ç»­å¯¹è¯...")
        print("-" * 60)
        print()
        
        messages.append(LLMMessage(role="assistant", content=full_response))
        messages.append(LLMMessage(
            role="user",
            content="å¾ˆå¥½ï¼é‚£ä½ èƒ½å¸®æˆ‘å†™ä¸€ä¸ª Python çš„ Hello World å—ï¼Ÿ"
        ))
        
        response_parts2 = []
        async for response in provider.stream(messages, max_tokens=300):
            if response.type == "text_delta":
                text = response.content
                response_parts2.append(text)
                print(text, end="", flush=True)
            elif response.type == "done":
                break
        
        print()
        print()
        print("-" * 60)
        print("=" * 60)
        print("ğŸ‰ æµ‹è¯•å®Œæˆï¼Gemini API å·¥ä½œæ­£å¸¸ï¼")
        print("=" * 60)
        print()
        print("âœ… æµ‹è¯•ç»“æœ:")
        print("   - API Key æœ‰æ•ˆ")
        print("   - æ¨¡å‹: Gemini 2.5 Flash")
        print("   - ä¸­æ–‡å¯¹è¯: æ­£å¸¸")
        print("   - å¤šè½®å¯¹è¯: æ­£å¸¸")
        print("   - ä»£ç ç”Ÿæˆ: æ­£å¸¸")
        print()
        print("ğŸš€ ClawdBot Python å·²å°±ç»ªï¼")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    print()
    print("âš ï¸  å®‰å…¨æé†’:")
    print("   - .env æ–‡ä»¶å·²åœ¨ .gitignore ä¸­")
    print("   - ä¸ä¼šä¸Šä¼ ä»»ä½•æ•æ„Ÿä¿¡æ¯åˆ° GitHub")
    print("   - åªè¿›è¡Œå®‰å…¨çš„å¯¹è¯æµ‹è¯•")
    print()
    
    asyncio.run(test_gemini_chat())
